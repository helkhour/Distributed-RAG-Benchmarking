end-to-end latency
throughput
embedding time between models : LM vs all-mpnet-base-v2 which has bigger context size

vector index optimization 
try with new numCandidates number ! "numCandidates": K * 100 instead of 10 DONE

mutable data 


Waiting for vector index to be ready... : this is too slow !! Whats wrong with index ? DONE 




My end goal is to figure out how many concurrent users could be supported before I'd need to scale up the instance size? 